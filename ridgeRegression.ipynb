{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo es intentar predecir el 'track_popularity' de cualquier canción.\n",
    "\n",
    "Para ello entrenaremos modelos de Regresión Ridge para las distintas versiones del dataset:\n",
    "- Datos escalados,\n",
    "- PCA de 6 componentes (sólo *musical features*),\n",
    "- PCA de 9 componentes *(incluye dummies de 'genre').*\n",
    "\n",
    "La mejor regresión de Ridge para cada conjunto de datos será utilizada como benchmark de referencia contra el que hacer luego las comparaciones, por tratarse de uno de los modelos más sencillos que se pueden aplicar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "from sklearn.metrics import (mean_absolute_error, r2_score,\n",
    "                             root_mean_squared_error, \n",
    "                             mean_absolute_percentage_error)\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/df_scaled.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['track_popularity']\n",
    "X = df.drop(columns=['track_popularity','track_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separamos el dataset en sets de entrenamiento y testeo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos una búsqueda de los mejores parámetros de Support Vector Regressor para nuestro dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea un modelo Ridge\n",
    "ridge_hitters = Ridge()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realiza una búsqueda de grilla para encontrar el parámetro óptimo de alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecución: 43.18820905685425\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time() # Inicia medición de tiempo de ejecución\n",
    "\n",
    "grid_ridge = GridSearchCV(ridge_hitters,\n",
    "                    {\"alpha\": np.linspace(0, 20, 1000)},\n",
    "                    refit=True,\n",
    "                    cv=5,\n",
    "                    scoring='neg_mean_absolute_error')\n",
    "grid_ridge.fit(X_train,y_train)\n",
    "\n",
    "end_time = time.time() # Finaliza medición de tiempo de ejecución\n",
    "\n",
    "# Calcula tiempo de ejecución\n",
    "total_time = end_time - start_time\n",
    "print(f\"Tiempo de ejecución: {total_time}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor modelo: Ridge(alpha=0.0)\n",
      "Guardado como 'models/ridge_scaled.pkl'\n"
     ]
    }
   ],
   "source": [
    "# Guardar los mejores parámetros de la búsqueda\n",
    "best_model = grid_ridge.best_estimator_\n",
    "\n",
    "# Exportación del modelo\n",
    "if best_model is not None:\n",
    "    model_save_path = \"models/ridge_scaled.pkl\"\n",
    "    with open(model_save_path, 'wb') as f:\n",
    "        pickle.dump(best_model, f)\n",
    "    print(f\"Mejor modelo: {best_model}\")\n",
    "    print(f\"Guardado como '{model_save_path}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estudio de métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE de testeo fue: 0.1528584508433987\n",
      "RMSE de testeo fue: 0.18614300092165012\n",
      "MAPE de testeo fue: 10824012387177.076\n",
      "R2 de testeo fue: 0.10833310045571798\n"
     ]
    }
   ],
   "source": [
    "ridge_hitters = grid_ridge.best_estimator_\n",
    "\n",
    "y_pred = ridge_hitters.predict(X_test)\n",
    "y_pred_ridge = y_pred\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MAE de testeo fue: {mae}\")\n",
    "print(f\"RMSE de testeo fue: {rmse}\")\n",
    "print(f\"MAPE de testeo fue: {mape}\")\n",
    "print(f\"R2 de testeo fue: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA 6 componentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/df_pca6.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['track_popularity']\n",
    "X = df.drop(columns=['track_popularity','track_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separamos el dataset en sets de entrenamiento y testeo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos una búsqueda de los mejores parámetros de Support Vector Regressor para nuestro dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea un modelo Ridge\n",
    "ridge_hitters = Ridge()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realiza una búsqueda de grilla para encontrar el parámetro óptimo de alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecución: 28.6592960357666\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time() # Inicia medición de tiempo de ejecución\n",
    "\n",
    "grid_ridge = GridSearchCV(ridge_hitters,\n",
    "                    {\"alpha\": np.linspace(0, 20, 1000)},\n",
    "                    refit=True,\n",
    "                    cv=5,\n",
    "                    scoring='neg_mean_absolute_error')\n",
    "grid_ridge.fit(X_train,y_train)\n",
    "\n",
    "end_time = time.time() # Finaliza medición de tiempo de ejecución\n",
    "\n",
    "# Calcula tiempo de ejecución\n",
    "total_time = end_time - start_time\n",
    "print(f\"Tiempo de ejecución: {total_time}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor modelo: Ridge(alpha=20.0)\n",
      "Guardado como 'models/ridge_pca6.pkl'\n"
     ]
    }
   ],
   "source": [
    "# Guardar los mejores parámetros de la búsqueda\n",
    "best_model = grid_ridge.best_estimator_\n",
    "\n",
    "# Exportación del modelo\n",
    "if best_model is not None:\n",
    "    model_save_path = \"models/ridge_pca6.pkl\"\n",
    "    with open(model_save_path, 'wb') as f:\n",
    "        pickle.dump(best_model, f)\n",
    "    print(f\"Mejor modelo: {best_model}\")\n",
    "    print(f\"Guardado como '{model_save_path}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estudio de métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE de testeo fue: 0.1613493145950062\n",
      "RMSE de testeo fue: 0.19428495851749936\n",
      "MAPE de testeo fue: 11000354431233.164\n",
      "R2 de testeo fue: 0.028623526703989377\n"
     ]
    }
   ],
   "source": [
    "ridge_hitters = grid_ridge.best_estimator_\n",
    "\n",
    "y_pred = ridge_hitters.predict(X_test)\n",
    "y_pred_ridge = y_pred\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MAE de testeo fue: {mae}\")\n",
    "print(f\"RMSE de testeo fue: {rmse}\")\n",
    "print(f\"MAPE de testeo fue: {mape}\")\n",
    "print(f\"R2 de testeo fue: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA 9 componentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/df_pca9.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['track_popularity']\n",
    "X = df.drop(columns=['track_popularity','track_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separamos el dataset en sets de entrenamiento y testeo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos una búsqueda de los mejores parámetros de Support Vector Regressor para nuestro dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea un modelo Ridge\n",
    "ridge_hitters = Ridge()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realiza una búsqueda de grilla para encontrar el parámetro óptimo de alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecución: 28.856944799423218\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time() # Inicia medición de tiempo de ejecución\n",
    "\n",
    "grid_ridge = GridSearchCV(ridge_hitters,\n",
    "                    {\"alpha\": np.linspace(0, 20, 1000)},\n",
    "                    refit=True,\n",
    "                    cv=5,\n",
    "                    scoring='neg_mean_absolute_error')\n",
    "grid_ridge.fit(X_train,y_train)\n",
    "\n",
    "end_time = time.time() # Finaliza medición de tiempo de ejecución\n",
    "\n",
    "# Calcula tiempo de ejecución\n",
    "total_time = end_time - start_time\n",
    "print(f\"Tiempo de ejecución: {total_time}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor modelo: Ridge(alpha=0.0)\n",
      "Guardado como 'models/ridge_pca9.pkl'\n"
     ]
    }
   ],
   "source": [
    "# Guardar los mejores parámetros de la búsqueda\n",
    "best_model = grid_ridge.best_estimator_\n",
    "\n",
    "# Exportación del modelo\n",
    "if best_model is not None:\n",
    "    model_save_path = \"models/ridge_pca9.pkl\"\n",
    "    with open(model_save_path, 'wb') as f:\n",
    "        pickle.dump(best_model, f)\n",
    "    print(f\"Mejor modelo: {best_model}\")\n",
    "    print(f\"Guardado como '{model_save_path}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estudio de métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE de testeo fue: 0.15929968290218816\n",
      "RMSE de testeo fue: 0.19202122403906738\n",
      "MAPE de testeo fue: 10918061186771.465\n",
      "R2 de testeo fue: 0.051127871184242446\n"
     ]
    }
   ],
   "source": [
    "ridge_hitters = grid_ridge.best_estimator_\n",
    "\n",
    "y_pred = ridge_hitters.predict(X_test)\n",
    "y_pred_ridge = y_pred\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MAE de testeo fue: {mae}\")\n",
    "print(f\"RMSE de testeo fue: {rmse}\")\n",
    "print(f\"MAPE de testeo fue: {mape}\")\n",
    "print(f\"R2 de testeo fue: {r2}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
